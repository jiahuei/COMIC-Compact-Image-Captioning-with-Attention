COMIC: Towards a Compact Image Captioning Model with Attention
===================

This is the code repo for the TMM 2019 paper "COMIC: Towards a Compact Image Captioning Model with Attention".

**Please NOTE that this code is NOT yet ready.**

```
@article{tan2019comic,
  title={COMIC: Towards A Compact Image Captioning Model with Attention},
  author={Tan, Jia Huei and Chan, Chee Seng and Chuah, Joon Huang},
  journal={IEEE Transactions on Multimedia},
  year={2019},
  publisher={IEEE}
}
```

### Requirements ##
- tensorflow r1.9.0
- python 2.7
- java 1.8.0
- tqdm >= 4.24.0
- requests >= 2.18.4
- Pillow >= 3.1.2


## Running the code ##
Assuming you are in the `src` folder:

1. Run `setup.sh` to download the required Stanford models 
and run all the dataset pre-processing scripts.

1. Run the training script `python train.py`. 
Examples are given in `example.sh`.


### Avoid redownloading datasets ###
Redownloading can be avoided by:
- Editing `setup.sh`
- Providing the path to the directory containing the dataset files

```bash
python coco_prepro.py --dataset_dir /path/to/coco/dataset
python insta_prepro.py --dataset_dir /path/to/insta/dataset
```

In the same way, both `train.py` and `infer.py` accept alternative dataset paths.

```bash
python train.py --dataset_dir /path/to/coco/dataset
python infer.py --dataset_dir /path/to/insta/dataset
```

This code assumes the following dataset directory structures:

#### MS-COCO
{coco-folder}
+-- captions
|   +-- {files generated by prepro scripts}
+-- test2014
|   +-- {image files}
+-- train2014
|   +-- {image files}
+-- val2014
    +-- {image files}

#### InstaPIC-1.1M
{insta-folder}
+-- captions
|   +-- {files generated by prepro scripts}
+-- images
|   +-- {image files}
+-- json
    +-- insta-caption-test1.json
    +-- insta-caption-train.json


### Differences compared to the paper ###
- Added attention map dropout
- RNN init method changed to `x_{t=-1} = W_I * I_{embed}`
from `h_{t=-1} = W_I tanh (LN (I_{embed} ))`
- Changed training scheme (LR, ADAM epsilon)
- Possible RNN variational dropout
- Possible context layer


### Microsoft COCO Caption Evaluation ###
This code uses the standard `coco-caption` code with *SPICE* metric.

[Link to repo](https://github.com/tylin/coco-caption/tree/3a9afb2682141a03e1cdc02b0df6770d2c884f6f)



